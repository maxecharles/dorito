{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"dorito","text":"<p><code>dorito</code> is an image reconstruction framework designed to interface with <code>amigo</code>, an end-to-end differentiable forward-modelling pipeline for analysing data from the Aperture Masking Interferometer (AMI) observing mode of the James Webb Space Telescope (JWST).</p> <p>Seen in the gif above are five successive images of Jupiter's moon Io that have been deconvolved with <code>dorito</code>, with the moon's axial rotation clearly visible. The right image shows the expected positions of known volcanic features on Io's hellscape of a surface!</p> <p>Please refer to our publications for more detail: amigo paper here, dorito paper here.</p> <p>We are working hard to create more documentation and example notebooks to share with the community here. Thank you for your patience, and please do not hesitate to reach out with any questions or queries. You can reach me (Max) at <pre><code>max.charles@sydney.edu.au\n</code></pre></p>"},{"location":"docs/examples/image_plane_fitting/","title":"Io Reconstruction in the Image Plane","text":"<p>In this notebook I will run through a basic example of an image reconstruction using Method 1 from the dorito paper.</p> <p>First we import our relevant libraries, and enable 64-bit float precision and (optionally) GPU usage.</p> <pre><code># jax ecosystem\nimport jax\nfrom jax import numpy as np  # apologies for this, but once you go jax you never go back\n\njax.config.update(\"jax_enable_x64\", True)  # using 64-bit precision is necessary\njax.config.update(\"jax_platform_name\", \"gpu\")  # for using GPU (optional)\nprint(jax.local_devices()[0].device_kind)\n</code></pre> <pre><code>NVIDIA GeForce RTX 2080 Ti\n</code></pre> <pre><code>import amigo  # for the amigo base model\nimport dorito  # for image reconstruction\nfrom zodiax.optimisation import sgd, adam  # for gradient descent\n\n# other helpful libraries\nimport os\nfrom dLux import utils as dlu  # for some optics utils functionality\n\n# matplotlib ecosystem\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nplt.rcParams[\"image.cmap\"] = \"inferno\"\nplt.rcParams[\"font.family\"] = \"serif\"\nplt.rcParams[\"image.origin\"] = \"lower\"\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"font.size\"] = 8\nplt.rcParams[\"xtick.direction\"] = \"out\"\nplt.rcParams[\"ytick.direction\"] = \"out\"\n</code></pre> <pre><code>/home/max/miniforge3/envs/newb/lib/python3.13/site-packages/amigo/optical_models.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  import pkg_resources as pkg\n</code></pre>"},{"location":"docs/examples/image_plane_fitting/#loading-in","title":"Loading in","text":"<p>Here we load in the data and relevant files to run the <code>amigo</code> model.</p> <pre><code>path_to_files = \"/media/morgana1/snert/max/data/\"\n\n# processed \"calslope\" files from the amigo pipeline\ndata_path = os.path.join(path_to_files, \"JWST/IO/calslope/\")\n\n# amigo files\nmodel_cache = os.path.join(path_to_files, \"amigo_files/v_0.0.10/\")\nfisher_path = os.path.join(path_to_files, \"amigo_files/fishers/\")\noutput_path = os.path.join(path_to_files, \"amigo_files/outputs/IO/\")\n\nprint(\"Data files:\")\nprint(os.listdir(data_path), \"\\n\")\nprint(\"Amigo model files:\")\nprint(os.listdir(model_cache), \"\\n\")\n</code></pre> <pre><code>Data files:\n['jw01373017001_04102_00001_nis_calslope.fits', 'jw01373023001_03102_00002_nis_calslope.fits', 'jw01373023001_03102_00003_nis_calslope.fits', 'jw01373023001_03102_00004_nis_calslope.fits', 'jw01373017001_04102_00005_nis_calslope.fits', 'jw01373023001_03102_00001_nis_calslope.fits', 'jw01373017001_04102_00002_nis_calslope.fits', 'jw01373017001_04102_00003_nis_calslope.fits', 'jw01373017001_04102_00004_nis_calslope.fits']\n\nAmigo model files:\n['jacobians.npy', 'calibration.npy', 'vis_basis.npy', 'calibration_2.npy', 'calibration_1.npy', 'im_basis101_1pix_M.npy']\n</code></pre> <p>Now we actually load the fits files, and set the bad pixels we want. We also truncate the ramp because the Io data is saturated, and we want to keep the pixel well depth below the that of data which was used to train the <code>amigo</code> model. </p> <pre><code>EXP_TYPE = \"NIS_AMI\"\nFILTERS = [\n    # \"F480M\",\n    \"F430M\",  # Io only had F430M exposures\n    # \"F380M\",\n]\n\n# Bind file path, type and exposure type\nfile_fn = lambda data_path, filters=FILTERS, **kwargs: amigo.files.get_files(\n    data_path,\n    \"calslope\",\n    EXP_TYPE=EXP_TYPE,\n    FILTER=FILTERS,\n    **kwargs,\n)\n\n# Here we load in the fits files\nfiles = sorted(\n    file_fn(data_path), key=lambda hdu: hdu[0].header.get(\"EXPMID\", float(\"inf\"))\n)\n\nsci_files = []\ncal_files = []\n\n# Here we manually set bad pixels in the BADPIX extension of the fits files\nfor file in files:\n\n    # manual bad pixel correction\n    file[\"BADPIX\"].data[58, 67] = 1\n    file[\"BADPIX\"].data[71, 22] = 1\n    file[\"BADPIX\"].data[65, 41] = 1\n    file[\"BADPIX\"].data[35, 70] = 1\n    file[\"BADPIX\"].data[70, 55] = 1\n    file[\"BADPIX\"].data[5, 5] = 1\n    file[\"BADPIX\"].data[-4, 37] = 1\n    file[\"BADPIX\"].data[51, 27] = 1\n    file[\"BADPIX\"].data[28, 18] = 1\n    file[\"BADPIX\"].data[32, 10] = 1\n\n    # edge bad pixels\n    file[\"BADPIX\"].data[:, :3] = 1\n    file[\"BADPIX\"].data[:, -3:] = 1\n    file[\"BADPIX\"].data[:3, :] = 1\n    file[\"BADPIX\"].data[-3:, :] = 1\n\n    if not bool(file[0].header[\"IS_PSF\"]):\n        file[\"BADPIX\"].data[43, 45] = 1\n        file[\"BADPIX\"].data[:, :10] = 1\n        file[\"BADPIX\"].data[:, -10:] = 1\n        file[\"BADPIX\"].data[:10, :] = 1\n        file[\"BADPIX\"].data[-10:, :] = 1\n        sci_files.append(file)\n    elif bool(file[0].header[\"IS_PSF\"]):\n        file[0].header[\"TARGPROP\"] = \"HD 228337\"\n        cal_files.append(file)\n    else:\n        print(f\"Unkown target: {file[0].header['TARGPROP']}\")\n\n# Here we truncate the ramp to keen the pixel well depth under 30k\ndorito.misc.truncate_files(sci_files, 18)\n</code></pre>"},{"location":"docs/examples/image_plane_fitting/#building-the-model","title":"Building the model","text":"<p>We are going to have to build the exposures. <code>dorito</code> has a <code>ResolvedFit</code> class built in, however this will jointly fit all exposures of the same filter. Since we want to capture Io's rotation in a time series, we instead want to uniquely fit each epoch. To do this, we will write a child class of <code>ResolvedFit</code> and amend the <code>get_key</code> method. By adding the <code>self.key</code> to the <code>log_dist</code> parameter key, this ensures each exposure will fit a unique distribution. In the <code>ResolvedFit</code> class, it is instead set just to <code>self.filter</code>, which is common for all the exposures and hence they will share the same parameter.</p> <p><code>DynamicResolvedFit</code> is also built into <code>dorito</code>, but it is useful to show how the classes are constructed. Once you get comfortable with setting the <code>get_key</code> class, <code>amigo</code> makes it very easy to quickly change the parameter fitting hierarchy.</p> <pre><code>class DynamicResolvedFit(dorito.model_fits.ResolvedFit):\n    \"\"\"\n    Model fit for resolved sources where each exposure has a different\n    intensity distribution.\n    \"\"\"\n\n    def get_key(self, param):\n        match param:\n            case \"log_dist\":\n                return \"_\".join([self.key, self.filter])\n\n        return super().get_key(param)\n</code></pre> <p>Now we will build the exposures and model. Today, to keep this simple, we will just fit two of the five Io exposures, and use one of the calibrator exposures.</p> <pre><code>load_dict = lambda x: np.load(f\"{x}\", allow_pickle=True).item()  # helper function\n\n# just two science exposures and one calibrator for this demo\nsci_exps = [DynamicResolvedFit(file) for file in sci_files[0:2]]\ncal_exps = [amigo.model_fits.PointFit(file) for file in cal_files[0:1]]\nexps = sci_exps + cal_exps\n\n# building the model\nsource_size = 101  # pixels\nmodel = dorito.models.ResolvedAmigoModel(\n    exposures=exps,\n    optics=amigo.optical_models.AMIOptics(),\n    detector=amigo.detector_models.LinearDetector(),\n    ramp_model=amigo.ramp_models.NonLinearRamp(),\n    read=amigo.read_models.ReadModel(),\n    state=load_dict(model_cache + \"calibration.npy\"),\n    param_initers={\n        \"distribution\": np.ones((source_size, source_size)) / source_size**2\n    },\n)\n</code></pre> <p>Let's have a look how the model fits the data at our initial guesses (it should be terrible)!</p> <pre><code>for exp in exps:\n    exp.print_summary()\n    amigo.plotting.summarise_fit(model, exp)\n</code></pre> <pre><code>File 01373_017_02_04_1\nStar IO\nFilter F430M\nnints 100\nngroups 18\n</code></pre> <p></p> <pre><code>File 01373_017_02_04_2\nStar IO\nFilter F430M\nnints 100\nngroups 18\n</code></pre> <p></p> <pre><code>File 01373_023_02_03_1\nStar HD 228337\nFilter F430M\nnints 8\nngroups 12\n</code></pre> <p></p>"},{"location":"docs/examples/image_plane_fitting/#optimisation-stage-gradient-descent","title":"Optimisation Stage: Gradient Descent","text":"<p>We now will fit the model using gradient descent, specifically using the <code>optax</code> library. Let's set some things up first.</p> <p>Firstly we have our <code>config</code> dictionary. You can see we are using a mixture of stochastic gradient descent and the adam optimiser. The <code>sgd</code> and <code>adam</code> functions from <code>zodiax</code> are just wrappers around the respective <code>optax</code> functions which allow for easy piecewise learning rate schedules.</p> <p>For example, <code>sgd(lr=100, start=50)</code> will cause a parameter to start fitting after 50 epochs with a learning rate of 100.</p> <pre><code>config = {\n    \"positions\": sgd(lr=4e-2, start=0),\n    \"fluxes\": sgd(2e-2, 0),\n    \"aberrations\": sgd(5e0, 4),\n    \"spectra\": sgd(1e-1, 10),\n    \"log_dist\": adam(5e-2, 20),\n}\n</code></pre> <p>Next we define a <code>norm_fn</code> or normalisation function, and a <code>grad_fn</code> or gradient function. These functions are applied each iteration of the fitting loop to the parameters or the parameter gradients respectively.</p>"},{"location":"docs/examples/image_plane_fitting/#normalisation-function","title":"Normalisation function","text":"<p>Because the source distribution values are covariant with the flux parameter, we want to normalise the source distribution every epoch so it will sum to unity. Additionally, if the <code>spectra</code> parameter wanders outside of \\([-1, 1]\\), everything will turn to <code>NaN</code>. To prevent this, we simply clip the value to \\([-0.8, 0.8]\\) to be extra safe.</p> <pre><code>def norm_fn(model_params, args):\n    params = model_params.params\n    if \"log_dist\" in params.keys():\n        for k, log_dist in params[\"log_dist\"].items():\n            distribution = 10**log_dist\n            params[\"log_dist\"][k] = np.log10(distribution / distribution.sum())\n\n    if \"spectra\" in params.keys():\n        spectra = jax.tree.map(\n            lambda x: np.clip(x, a_min=-0.8, a_max=0.8), params[\"spectra\"]\n        )\n        params[\"spectra\"] = spectra\n\n    return model_params.set(\"params\", params), args\n</code></pre>"},{"location":"docs/examples/image_plane_fitting/#gradient-function","title":"Gradient function","text":"<p>Because we are fitting the Io science exposures separately, they do not mutually constrain the position of the source distribution array. Because of this, we do not fit the positions of the science exposures, as the initial guess will be sufficient to place them in the correct part of the detector. We implement this by simply multiplying the gradients by zero in the <code>grad_fn</code>.</p> <p>I have also observed when fitting Io that the gradients of <code>spectra</code> for the science and calibrator exposures tend to be quite different. Because of this, in the <code>grad_fn</code> I reduce the gradients only for the science exposures by a heuristic factor.</p> <pre><code>sci_pos_keys = []\nsci_spc_keys = []\nfor exp in exps:\n    if not exp.calibrator:\n        sci_pos_keys.append(exp.map_param(\"positions\"))\n        sci_spc_keys.append(exp.map_param(\"spectra\"))\n\n\ndef grad_fn(model, grads, args):\n    # Nuke the position gradients for the science exposures\n    if \"positions\" in config.keys():\n        grads = grads.multiply(sci_pos_keys, 0.0)\n\n    # Reduce spectra gradients for the science exposures\n    if \"spectra\" in config.keys():\n        grads = grads.multiply(sci_spc_keys, 1e-2)\n    return grads, args\n</code></pre>"},{"location":"docs/examples/image_plane_fitting/#regularisation","title":"Regularisation","text":"<p><code>dorito</code> has some common image regularisers built in. Here we will use total variation (<code>dorito.stats.TV</code>), which we put into the <code>args dictionary</code> which we will pass to our <code>Trainer</code> class.</p> <p>For this to work we will need to also pass the <code>dorito.stats.ramp_regularised_loss_fn</code> as the loss function to the <code>Trainer</code> class, as the default <code>amigo</code> loss function knows not of regularisation.</p> <pre><code>args = {\"reg_dict\": {\"TV\": (5e0, dorito.stats.TV)}}\n</code></pre>"},{"location":"docs/examples/image_plane_fitting/#fitting","title":"Fitting","text":"<p>We are almost ready to fit. Here we initialise the <code>Trainer</code> class from <code>amigo</code> and populate the Fisher matrices. These Fisher matrices are not crucial: they are simply pre-calculated matrices which scale the loss space in order to improve convergence, but with plenty of learning rate tweaking you will reach the same result. This is the case for the <code>log_dist</code> parameter which does not have any pre-calculated matrices!</p> <p>Lastly, we perform the fit!</p> <pre><code>n_epoch = 1000\n\ntrainer = amigo.fitting.Trainer(\n    loss_fn=dorito.stats.ramp_regularised_loss_fn,\n    norm_fn=norm_fn,\n    grad_fn=grad_fn,\n    cache=os.path.join(fisher_path),\n)\n\nprint(\"Populating fishers...\")\ntrainer = trainer.populate_fishers(\n    model,\n    exps,\n    hessians=load_dict(model_cache + \"jacobians.npy\")[\"hessian\"],\n    parameters=[p for p in config.keys()],\n)\n\nprint(\"Number of exposures: \", len(exps))\n\n# Train the model\nresult = trainer.train(\n    model=model,\n    optimisers=config,\n    epochs=n_epoch,\n    batches=exps,\n    args=args,\n)\n</code></pre> <pre><code>Populating fishers...\nKeyError: log_dist not in hessians for 01373_017_02_04_1, skipped\nKeyError: log_dist not in hessians for 01373_017_02_04_2, skipped\nKeyError: log_dist not in hessians for 01373_023_02_03_1, skipped\nNumber of exposures:  3\n\n\n\n  0%|          | 0/1000 [00:00&lt;?, ?it/s]\n\n\nCompiling Loss function...\nCompiling update function...\n\nInitial_loss Loss: 120,196.88\nEstimated run time: 0:20:16\nFull Time: 0:21:54\nFinal Loss: 24.42\n</code></pre>"},{"location":"docs/examples/image_plane_fitting/#results","title":"Results","text":"<p>Let's have a look at how our fit went.</p> <pre><code>amigo.plotting.plot_losses(result.losses[0], start=int(n_epoch * 0.75))\namigo.plotting.plot(result.history)\n\nfor exp in exps:\n    exp.print_summary()\n    amigo.plotting.summarise_fit(result.model, exp)\n</code></pre> <p></p> <p></p> <p></p> <p></p> <pre><code>File 01373_017_02_04_1\nStar IO\nFilter F430M\nnints 100\nngroups 18\n</code></pre> <p>Nice. Some of the parameters are not entirely converged, and this can be improved by running the fit for more epochs, or by passing the fit model to another optimiser. We have seen some success with <code>optimistix.BFGS</code>. This is especially true of the <code>spectra</code> parameter for Io, where you can see the effect of spectral miscalibration in the residuals. </p> <p>But this will do nicely for now \u2014 let's see our images!</p> <pre><code>optics_diameter = 6.603464  # JWST aperture diameter in meters\nwavel = 4.3e-6  # approximate F430M mean wavelength in meters\n\nfor idx, exp in enumerate(exps):\n\n    # only plot science exposures\n    if exp.calibrator:\n        continue\n\n    dist = result.model.get_distribution(exp, rotate=False)\n    fig, ax = plt.subplots(figsize=(6, 2.3))\n\n    c0 = dorito.plotting.plot_result(\n        ax,\n        dist / dist.max(),\n        pixel_scale=model.psf_pixel_scale / model.oversample,\n        cmap=\"inferno\",\n        norm=mpl.colors.PowerNorm(0.6, vmin=0, vmax=1.0),\n        diff_lim=0.5 * dlu.rad2arcsec(wavel / optics_diameter),\n        scale=1.2,\n    )\n    fig.colorbar(c0)\n    ax.set(title=f\"Io Frame {idx}\")\n    plt.show()\n</code></pre> <p></p> <p></p> <pre><code>\n</code></pre>"}]}